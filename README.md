# ğŸ§  MLOps Iris Project

## ğŸ¯ Objectif
Ce projet a pour but de mettre en place une **stack MLOps complÃ¨te** permettant de :

- entraÃ®ner un modÃ¨le de machine learning
- tracer les expÃ©riences (paramÃ¨tres, mÃ©triques, modÃ¨les)
- stocker les artifacts de maniÃ¨re persistante
- exposer une API de prÃ©diction
- orchestrer lâ€™ensemble avec Docker Compose

ğŸ‘‰ Il sâ€™agit dâ€™un **mini-projet MLOps rÃ©aliste**, proche dâ€™une architecture production.

---

## ğŸ§± Architecture

### Services principaux
- **trainer** : job batch dâ€™entraÃ®nement du modÃ¨le
- **mlflow** : tracking server (experiments, runs, artifacts)
- **api** : API FastAPI pour servir le modÃ¨le
- **volumes Docker** : persistance des donnÃ©es et modÃ¨les



## ğŸ§± Architecture

### Services principaux
- **trainer** : job batch dâ€™entraÃ®nement du modÃ¨le
- **mlflow** : tracking server (experiments, runs, artifacts)
- **api** : API FastAPI pour servir le modÃ¨le
- **volumes Docker** : persistance des donnÃ©es et modÃ¨les


---
![alt text](image.png)
---

## ğŸ“ Structure du projet

![alt text](arbonescence.png)

## ğŸ” Pipeline MLOps

### 1ï¸âƒ£ EntraÃ®nement (trainer)
- Chargement du dataset Iris
- EntraÃ®nement dâ€™un `RandomForestClassifier`
- Logging dans MLflow :
  - paramÃ¨tres (ex: `n_estimators`)
  - mÃ©triques (`accuracy`)
  - artifacts (modÃ¨le, environnement, metadata)
- Sauvegarde du modÃ¨le dans un volume Docker partagÃ©

### 2ï¸âƒ£ Tracking (MLflow)
- Interface MLflow disponible sur :  
  ğŸ‘‰ `http://localhost:5000`
- Visualisation :
  - Experiments
  - Runs
  - Metrics
  - Artifacts
- Chaque entraÃ®nement est **traÃ§able et reproductible**

### 3ï¸âƒ£ Serving (API FastAPI)
- Chargement du modÃ¨le entraÃ®nÃ©
- Endpoints disponibles :
  - `GET /health`
  - `POST /predict`
- Documentation Swagger :
  ğŸ‘‰ `http://localhost:8000/docs`

---

## ğŸ“¦ Stockage & persistance

### Volumes Docker
| Volume | RÃ´le |
|------|----|
| `model_data` | ModÃ¨le utilisÃ© par lâ€™API |
| `mlflow_data` | Base de donnÃ©es MLflow (SQLite) |
| `mlflow_artifacts` | Artifacts MLflow (modÃ¨les, fichiers) |

Les donnÃ©es sont persistantes mÃªme aprÃ¨s arrÃªt des conteneurs.

---

## ğŸš€ Lancer le projet

### PrÃ©requis
- Docker
- Docker Compose

### DÃ©marrer MLflow
```bash
docker compose up -d mlflow

docker compose up --build trainer



ğŸ§ª Tester lâ€™API
Health check

curl http://localhost:8000/health

PrÃ©diction
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features":[5.1,3.5,1.4,0.2]}'


ğŸ§  Concepts MLOps abordÃ©s

Docker Compose multi-services

Job batch vs service long-running

MLflow Tracking (experiments, runs, artifacts)

SÃ©paration training / serving

Persistance via volumes Docker

Debug MLflow (artifact_uri, proxy artifacts, sÃ©curitÃ© Host)

ğŸ”® Ã‰volutions possibles

MLflow Model Registry (Production / Staging)

API branchÃ©e directement sur MLflow (models:/â€¦)

Stockage S3 via MinIO

CI/CD (training et dÃ©ploiement automatisÃ©s)

ğŸ‘¤ Auteur

Projet rÃ©alisÃ© dans un objectif de montÃ©e en compÃ©tences MLOps.


---

## ğŸ§© What I learned

Through this project, I implemented and understood key MLOps concepts:

- Designing a multi-service architecture with Docker Compose
- Separating training (batch job) and serving (API)
- Experiment tracking with MLflow (params, metrics, artifacts)
- Debugging MLflow artifacts and tracking configuration
- Managing persistence with Docker volumes
- Understanding tracking vs serving vs registry
- Exposing ML models through a REST API (FastAPI)
- Building a reproducible and explainable ML pipeline

This project reflects how an ML system can be structured in a real-world environment.
